# Отток клиентов

## Описание проекта

**Набор данных**

Источник данных: [https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling](https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling)
- RowNumber — индекс строки в данных
- CustomerId — уникальный идентификатор клиента
- Surname — фамилия
- CreditScore — кредитный рейтинг
- Geography — страна проживания
- Gender — пол
- Age — возраст
- Tenure — сколько лет человек является клиентом банка
- Balance — баланс на счёте
- NumOfProducts — количество продуктов банка, используемых клиентом
- HasCrCard — наличие кредитной карты
- IsActiveMember — активность клиента
- EstimatedSalary — предполагаемая зарплата

**Целевой признак**
- Exited — факт ухода клиента

**Цель исследования**

Из Банка стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.

Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Нам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. 

Построим модель с предельно большим значением *F1*-меры.

Дополнительно измерим *AUC-ROC*, сравнивним её значение с *F1*-мерой.

**Ход исследования**
- Изучение данных
- Поиск лучшей модели и ее гиперпараметров
- Оценка влияния дисбаланса классов на результаты моделей
- Тестирование влияния порога классификации

## Инструменты
-  Matplotlib
-  Numpy
-  Pandas
-  Seaborn
-  Sklearn
    - Random forest classifier
    - Logistic regression
    - Decision treec lassifier
    - F1 score
    - Confusion matrix
    - Recall score
    - Precision score 
    - Precision recall curve
    - ROC-AUC score
    - ROC curve
    - Train test split
    - Ordinal encoder
    - Standard scaler
    - Shuffle

## Выводы

С учетом дисбаланса классов и без него лучший показатели имели модели случайного леса.

При попытке балансировки показателей езменения порога классификации не принеслo лучших результатов.

Также, была взята модель случайного леса без гиперпараметра class_weight='balanced' и протестирована на upsampled и downsampled выборках. Результаты отображены в таблице выше.

В итоге лучшей себя показала модель случайного леса с гиперпараметром class_weight='balanced', на ней и провели тестирование и получили следующие показатели:

- Recall: 0.69
- Precision: 0.58
- F1: 0.63
- AUC-ROC: 0.86