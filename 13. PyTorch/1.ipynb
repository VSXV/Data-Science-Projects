{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from math import ceil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://code.s3.yandex.net/datasets/6_class.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка и анализ данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num(column):\n",
    "    print(column,  '\\\\n')\n",
    "    print(df[column].describe())\n",
    "\n",
    "    figure, axis = plt.subplots(1, 2, figsize=(13,5))\n",
    "\n",
    "    plt.style.use('bmh')\n",
    "\n",
    "    axis[0].hist(df[column])\n",
    "    axis[0].set_title('График распределения значений')\n",
    "\n",
    "    axis[1].boxplot(df[column])\n",
    "    axis[1].set_title('График размаха значений')\n",
    "\n",
    "    figure.suptitle(column)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = ['Temperature (K)', 'Luminosity(L/Lo)', 'Radius(R/Ro)', 'Absolute magnitude(Mv)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numeric:\n",
    "    num(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы по количестенным признакам\n",
    "\n",
    "1. Основная масса представленных температур звезд находится в диапозоне до 6и тысяч. Низкая представленность других объектов.\n",
    "2. По светимости ситуация похожая, больше половины объектов практически не имеют светимости.\n",
    "3. Почти 90% объектов имеют радиус меньше 250, представленнось других объектов минимальна.\n",
    "4. Масса звезд распределенна округ двух показателей: около -7 и около 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat(column):\n",
    "    print(column, '\\\\n')\n",
    "    print(df[column].value_counts())\n",
    "\n",
    "    names = list(df[column].value_counts().index)\n",
    "    values = list(df[column].value_counts().values)\n",
    "\n",
    "    figure, axis = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "    axis.barh(names, values)\n",
    "\n",
    "    plt.style.use('bmh')\n",
    "\n",
    "    figure.suptitle(column)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['Star type', 'Star color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Star color'] = df['Star color'].str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Star color'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Star color'] = df['Star color'].replace({'blue white': 'blue',\n",
    "                                             'yellowish white': 'yellow',\n",
    "                                             'pale yellow orange': 'yellow',\n",
    "                                             'blue-white': 'blue',\n",
    "                                             'whitish': 'white',\n",
    "                                             'yellow-white': 'yellow',\n",
    "                                             'white-yellow': 'yellow',\n",
    "                                             'yellowish': 'yellow',\n",
    "                                             'orange-red': 'red'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical:\n",
    "    cat(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы по категориальным признакам\n",
    "\n",
    "1. Распределение объектов по типу является равномерным.\n",
    "2. 90% объектов являются голубыми или красными планетами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Temperature (K)\"]\n",
    "X = df.drop(\"Temperature (K)\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Star color'] = OrdinalEncoder().fit_transform(X[['Star color']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "columns_X = X.columns\n",
    "X = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X, columns=columns_X)\n",
    "\n",
    "del scaler\n",
    "del columns_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.FloatTensor(X_train.values) \n",
    "X_test_tensor = torch.FloatTensor(X_test.values)\n",
    "y_train_tensor = torch.FloatTensor(y_train.values)\n",
    "y_test_tensor = torch.FloatTensor(y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы по данным\n",
    "\n",
    "Колличество данных является небольшим и большенство из их признаков сконцентрированны у одних показателей, что может негативно сказаться на качестве предсказаний у объектов с низкой представленностью."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение базовой нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000\n",
    "learning_rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(layer):\n",
    "    if type(layer) == nn.Linear: \n",
    "        nn.init.normal_(layer.weight, mean=0.0, std=1.14)\n",
    "        nn.init.normal_(layer.bias, mean=-0.5, std=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_loss_1 = [] \n",
    "results_time_1 = [] \n",
    "results_loss_2 = [] \n",
    "\n",
    "n_in_neurons = 5\n",
    "n_hidden_neurons_1 = 10\n",
    "n_hidden_neurons_2 = 10\n",
    "n_out_neurons = 1 \n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(n_in_neurons, n_hidden_neurons_1),\n",
    "    nn.ELU(),\n",
    "    nn.Linear(n_hidden_neurons_1, n_hidden_neurons_2),\n",
    "    nn.ELU(),\n",
    "    nn.Linear(n_hidden_neurons_2, n_out_neurons),\n",
    "    nn.ReLU()\n",
    ")\n",
    "\n",
    "net.apply(init_weights)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    optimizer.zero_grad()\n",
    "    preds = net.forward(X_train_tensor).flatten()\n",
    "        \n",
    "    loss_value = loss(preds, y_train_tensor)\n",
    "    loss_value.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():   \n",
    "            net.eval()\n",
    "            test_preds = net.forward(X_test_tensor).flatten()\n",
    "            loss_value_test = loss(test_preds, y_test_tensor) \n",
    "            print('epoch {}, RMSE train {:.4f}, RMSE test {:.4f}'.format(epoch, torch.Tensor.sqrt_(loss_value),\\\n",
    "                                                                            torch.Tensor.sqrt_(loss_value_test)))                \n",
    "            \n",
    "            results_loss_1.append(loss_value.tolist())\n",
    "            results_time_1.append(epoch)\n",
    "            results_loss_2.append(loss_value_test.tolist())\n",
    "                \n",
    "results_loss_1 = pd.Series(results_loss_1)\n",
    "results_time_1 = pd.Series(results_time_1)\n",
    "results_loss_2 = pd.Series(results_loss_2)\n",
    "\n",
    "best_idx = results_loss_2.idxmin()\n",
    "\n",
    "print('')\n",
    "print('Лучшее значение RMSE test: ', results_loss_2[best_idx])\n",
    "print('RMSE train: ', results_loss_1[best_idx])\n",
    "print('Epoch: ', results_time_1[best_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graphic(target, preds):\n",
    "    figure, axis = plt.subplots(1, 1, figsize=(32,8))\n",
    "    \n",
    "    plt.style.use('bmh')\n",
    "\n",
    "    axis.bar(x = target.index, height = preds.int(), width = 3, alpha=0.5, label = 'Прогноз', color='blue')\n",
    "    axis.bar(x = target.index, height = target.values, width = 1, label = 'Факт', color='orange')\n",
    "\n",
    "    plt.xlabel(\"Номер звезды в таблице данных\")\n",
    "    plt.ylabel(\"Температура звезды\")\n",
    "\n",
    "    figure.suptitle('График')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_graphic(y_test, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы по бэйзлайну,\n",
    "\n",
    "Базоная нейронная сеть быстро обучается и показывает хорошие результаты на тестовой выборке.\n",
    "Скорость обучения достигается за счет небольшого количества данных и небольшого количества признаков.\n",
    "Можно заметить, что объекты с низкой представленностью в данных показывают худшие результаты, а именно объекты с высокой температурой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Улучшение нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_n, X_valid_n, y_train_n, y_valid_n = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "print(X_train_n.shape, y_train_n.shape, X_valid_n.shape, y_valid_n.shape)\n",
    "X_train_n_tensor = torch.FloatTensor(X_train_n.values) \n",
    "X_valid_n_tensor = torch.FloatTensor(X_valid_n.values)\n",
    "y_train_n_tensor = torch.FloatTensor(y_train_n.values)\n",
    "y_valid_n_tensor = torch.FloatTensor(y_valid_n.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_loss_1 = [] \n",
    "results_time_1 = [] \n",
    "results_loss_2 = []\n",
    "do1 = []\n",
    "do2 = []\n",
    "preds_2 = []\n",
    "\n",
    "p1 = [.1, .2, .5, .8]\n",
    "p2 = p1\n",
    "\n",
    "num_epochs = 5_000\n",
    "\n",
    "p1 = [.2, .5, .8]\n",
    "p2 = p1\n",
    "\n",
    "num_epochs = 10_000\n",
    "\n",
    "for v1 in p1:\n",
    "        for v2 in p2:\n",
    "                net2 = nn.Sequential(\n",
    "                nn.Linear(n_in_neurons, n_hidden_neurons_1),\n",
    "                nn.ELU(),\n",
    "                nn.Dropout(p=v1),\n",
    "                nn.Linear(n_hidden_neurons_1, n_hidden_neurons_2),\n",
    "                nn.ELU(),\n",
    "                nn.Dropout(p=v2),\n",
    "                nn.Linear(n_hidden_neurons_2, n_out_neurons),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "\n",
    "                net2.apply(init_weights)\n",
    "                optimizer = torch.optim.Adam(net2.parameters(), lr=learning_rate)\n",
    "                loss = nn.MSELoss()\n",
    "                for epoch in range(num_epochs):\n",
    "                        net2.train()\n",
    "                        optimizer.zero_grad()\n",
    "                        preds = net2.forward(X_train_n_tensor).flatten()\n",
    "                        \n",
    "                        loss_value = loss(preds, y_train_n_tensor)\n",
    "                        loss_value.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                        with torch.no_grad():   \n",
    "                                net2.eval()\n",
    "                                valid_preds = net2.forward(X_valid_n_tensor).flatten()\n",
    "                                loss_value_valid = loss(valid_preds, y_valid_n_tensor) \n",
    "                                print('Do1 {}, Do2 {}, epoch {}, RMSE train {:.4f}, RMSE valid {:.4f}'.format(v1, v2, epoch, torch.Tensor.sqrt_(loss_value),\\\n",
    "                                        torch.Tensor.sqrt_(loss_value_valid)))                \n",
    "                        \n",
    "                                \n",
    "                                results_loss_1.append(loss_value.tolist())\n",
    "                                results_time_1.append(epoch)\n",
    "                                results_loss_2.append(loss_value_valid.tolist())\n",
    "                                do1.append(v1)\n",
    "                                do2.append(v2)\n",
    "                                preds_2.append(valid_preds)\n",
    "\n",
    "results_loss_1 = pd.Series(results_loss_1)\n",
    "results_time_1 = pd.Series(results_time_1)\n",
    "results_loss_2 = pd.Series(results_loss_2)\n",
    "do1 = pd.Series(do1)\n",
    "do2 = pd.Series(do2)\n",
    "\n",
    "best_idx = results_loss_2.idxmin()\n",
    "        \n",
    "print('')\n",
    "print('Лучшее значение RMSE valid: ', results_loss_2[best_idx])\n",
    "print('RMSE train: ', results_loss_1[best_idx])\n",
    "print('Dropout 1: ', do1[best_idx])\n",
    "print('Dropout 2: ', do2[best_idx])\n",
    "print('Epoch: ', results_time_1[best_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_graphic(y_valid_n, preds_2[best_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы по модели с подбором Дропаута\n",
    "\n",
    "Из-за применения дропаута, модель использует в 3 раза больше эпох для обучения, но показывает немногого улучшенные показатели ошибки на валидационной выборке при дропауте в 10%.\n",
    "Проблема с низкой представленностью объектов также влияет на качество предсказаний."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_loss_3 = []\n",
    "results_time_3 = []\n",
    "results_size_3 = []\n",
    "result_loss_value_3 = []\n",
    "preds_3 = []\n",
    "\n",
    "net3 = nn.Sequential(\n",
    "    nn.Linear(n_in_neurons, n_hidden_neurons_1),\n",
    "    nn.ELU(),\n",
    "    nn.BatchNorm1d(n_hidden_neurons_1),    \n",
    "    nn.Linear(n_hidden_neurons_1, n_hidden_neurons_2),\n",
    "    nn.ELU(),\n",
    "    nn.BatchNorm1d(n_hidden_neurons_2),    \n",
    "    nn.Linear(n_hidden_neurons_2, n_out_neurons),\n",
    "    nn.ReLU()\n",
    ")\n",
    "\n",
    "\n",
    "bs = [5, 10, 25, 100]\n",
    "\n",
    "net3.apply(init_weights)\n",
    "optimizer = torch.optim.Adam(net3.parameters(), lr=learning_rate)\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "for batch_size in bs:\n",
    "    num_batches = ceil(len(X_train_n_tensor)/batch_size)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        order = np.random.permutation(len(X_train_n_tensor))\n",
    "        net3.train()\n",
    "        optimizer.zero_grad()\n",
    "        for batch_i in range(num_batches):\n",
    "            start_index = batch_i * batch_size\n",
    "            \n",
    "            batch_indexes = order[start_index:start_index+batch_size]\n",
    "            X_batch = X_train_n_tensor[batch_indexes]\n",
    "            y_batch = y_train_n_tensor[batch_indexes]\n",
    "        \n",
    "            preds = net3.forward(X_batch) \n",
    "                    \n",
    "            loss_value = loss(preds, y_batch)\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                    \n",
    "                        net3.eval()\n",
    "                        test_preds = net3.forward(X_valid_n_tensor).flatten()\n",
    "                        loss_value_valid = loss(test_preds, y_valid_n_tensor)\n",
    "\n",
    "                        print('size {}, epoch {}, RMSE train {:.4f}, RMSE valid {:.4f}'.format(batch_size, epoch, \\\n",
    "                                torch.Tensor.sqrt_(loss_value), torch.Tensor.sqrt_(loss_value_valid)))\n",
    "                        \n",
    "                        results_loss_3.append(loss_value_valid.tolist())\n",
    "                        result_loss_value_3.append(loss_value.tolist())\n",
    "                        results_time_3.append(epoch)\n",
    "                        results_size_3.append(batch_size)\n",
    "                        preds_3.append(valid_preds)\n",
    "\n",
    "results_loss_3 = pd.Series(results_loss_3)\n",
    "result_loss_value_3 = pd.Series(result_loss_value_3)\n",
    "results_time_3 = pd.Series(results_time_3)\n",
    "results_size_3 = pd.Series(results_size_3)\n",
    "\n",
    "best_idx = results_loss_3.idxmin()\n",
    "\n",
    "\n",
    "print('')\n",
    "print('Лучшее значение RMSE valid: ', results_loss_3[best_idx])\n",
    "print('RMSE train: ', result_loss_value_3[best_idx])\n",
    "print('Epoch: ', results_time_3[best_idx])\n",
    "print('Batch size: ', results_size_3[best_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_graphic(y_valid_n, preds_3[best_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы по модели с подбором размера батч\n",
    "    \n",
    "Из-за использования батчей модель показывает худшие результаты на валидационной выборке, чем без батчей. Скорее всего это связано с распределением признаков. Они влияют и на другие архитектуры, но, возможно, на подход с батчами сильнее всего."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_epoches = 1815\n",
    "\n",
    "final_net = nn.Sequential(\n",
    "            nn.Linear(n_in_neurons, n_hidden_neurons_1),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=.1),\n",
    "            nn.Linear(n_hidden_neurons_1, n_hidden_neurons_2),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=.1),\n",
    "            nn.Linear(n_hidden_neurons_2, n_out_neurons),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "final_net.apply(init_weights)\n",
    "optimizer = torch.optim.Adam(final_net.parameters(), lr=learning_rate)\n",
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(final_epoches):\n",
    "    final_net.train()\n",
    "    optimizer.zero_grad()\n",
    "    final_train_preds = final_net.forward(X_train_tensor).flatten()\n",
    "    \n",
    "    loss_value = loss(final_train_preds, y_train_tensor)\n",
    "    loss_value.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_net.eval()\n",
    "final_test_preds = final_net.forward(X_test_tensor).flatten()\n",
    "loss_value_valid = loss(final_test_preds, y_test_tensor) \n",
    "print('Финальное значение RMSE : ', torch.Tensor.sqrt_(loss_value_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основной критерий влияющий на качество оценки модели это представленность объектов в данных. Объекты редко представленные в датасете показывают худшие результаты. Если и в будущем объектов, с которыми нужно работать, будет не много, то стоит усложнить модель и подобрать новые гиперпараметры для улучшения качества предсказаний."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
