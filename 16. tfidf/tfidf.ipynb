{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Подготовка-данных\" data-toc-modified-id=\"Подготовка-данных-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Подготовка данных</a></span></li></ul></li><li><span><a href=\"#Вывод:\" data-toc-modified-id=\"Вывод:-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Вывод:</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Обучим-следующие-модели:\" data-toc-modified-id=\"Обучим-следующие-модели:-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Обучим следующие модели:</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/vs/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/vs/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/vs/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "\n",
    "from IPython.display import display\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tqdm import notebook\n",
    "\n",
    "m = WordNetLemmatizer() \n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "notebook.tqdm.pandas()\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "display(data.head())\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic\n",
       "0    143106\n",
       "1     16186\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "toxic\n",
       "0    89.84%\n",
       "1    10.16%\n",
       "Name: proportion, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(data['toxic'].value_counts())\n",
    "data['toxic'].value_counts(normalize=True).map('{:.2%}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Целевой признак с очень большим дисбалансом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_tokenize(text):\n",
    "    \n",
    "    tokenized = nltk.word_tokenize(text)\n",
    "    tagged = nltk.pos_tag(tokenized)\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    lemmatized_words = []\n",
    "    for word, tag in tagged:\n",
    "        pos = get_wordnet_pos(tag)\n",
    "        lemmatized_word = lemmatizer.lemmatize(word, pos=pos) if pos else lemmatizer.lemmatize(word)\n",
    "        lemmatized_words.append(lemmatized_word)\n",
    "\n",
    "    result = ' '.join(lemmatized_words)\n",
    "    result = re.sub(r'[^a-zA-Z]', ' ', result)\n",
    "    result = ' '.join(result.split())\n",
    "\n",
    "    return result\n",
    "\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('N'):\n",
    "        return 'n'  # Noun\n",
    "    elif tag.startswith('V'):\n",
    "        return 'v'  # Verb\n",
    "    elif tag.startswith('R'):\n",
    "        return 'r'  # Adverb\n",
    "    elif tag.startswith('J'):\n",
    "        return 'a'  # Adjective\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d6c300541b34da88f476aec76c7a062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv('data.csv')\n",
    "    print('data is ready', data.shape)\n",
    "except:\n",
    "    notebook.tqdm.pandas() \n",
    "    data['text_final'] = data['text'].progress_apply(text_tokenize)\n",
    "    try:\n",
    "        data.to_csv('data.csv', index=False)\n",
    "    except:\n",
    "        print('Ошибка сохранения файла')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Explanation Why the edits make under my username Hardcore Metallica Fan be revert They be n t vandalisms just closure on some GAs after I vote at New York Dolls FAC And please do n t remove the template from the talk page since I m retired now'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data['text_final'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data['text_final']\n",
    "target = data['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119469,)\n",
      "(119469,)\n",
      "(19911,)\n",
      "(19911,)\n",
      "(19912,)\n",
      "(19912,)\n"
     ]
    }
   ],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features, target, random_state=12345, \n",
    "                                                                            stratify=target)\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_test, target_test, random_state=12345, test_size=.5)\n",
    "print(features_train.shape)\n",
    "print(target_train.shape)\n",
    "print(features_valid.shape)\n",
    "print(target_valid.shape)\n",
    "print(features_test.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распределение классов в обучающей выборке:\n",
      "0.8983836811222995\n",
      "0.10161631887770049\n",
      "\n",
      "Распределение классов в валидационной выборке:\n",
      "0.8974436241273668\n",
      "0.10255637587263322\n",
      "\n",
      "Распределение классов в тестовой выборке:\n",
      "0.8993571715548413\n",
      "0.1006428284451587\n"
     ]
    }
   ],
   "source": [
    "print('Распределение классов в обучающей выборке:')\n",
    "print(target_train.value_counts()[0] / target_train.value_counts().sum())\n",
    "print(target_train.value_counts()[1] / target_train.value_counts().sum())\n",
    "print()\n",
    "print('Распределение классов в валидационной выборке:')\n",
    "print(target_valid.value_counts()[0] / target_valid.value_counts().sum())\n",
    "print(target_valid.value_counts()[1] / target_valid.value_counts().sum())\n",
    "print()\n",
    "print('Распределение классов в тестовой выборке:')\n",
    "print(target_test.value_counts()[0] / target_test.value_counts().sum())\n",
    "print(target_test.value_counts()[1] / target_test.value_counts().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/vs/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = list(set(nltk_stopwords.words('english')))\n",
    "display(len(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer(stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_data_tf_idf = tf_idf.fit_transform(features_train)\n",
    "features_valid_data_tf_idf = tf_idf.transform(features_valid)\n",
    "features_test_data_tf_idf = tf_idf.transform(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF train\n",
      "(119469, 136275)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "TF-IDF valid\n",
      "(19911, 136275)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "TF-IDF test\n",
      "(19912, 136275)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print('TF-IDF train')\n",
    "print(features_train_data_tf_idf.shape)\n",
    "print(features_train_data_tf_idf[:5].toarray())\n",
    "print()\n",
    "print('TF-IDF valid')\n",
    "print(features_valid_data_tf_idf.shape)\n",
    "print(features_valid_data_tf_idf[:5].toarray())\n",
    "print()\n",
    "print('TF-IDF test')\n",
    "print(features_test_data_tf_idf.shape)\n",
    "print(features_test_data_tf_idf[:5].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод:\n",
    "\n",
    "* Токенизировали и лемматизировали столбец text и добавили данные в столбец text_final\n",
    "* Провели оценку важности слов определением величины TF-IDF\n",
    "* Проверили данные после векторизации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучим следующие модели:\n",
    "\n",
    "* LogisticRegression\n",
    "* RandomForestClassifier\n",
    "* DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=500, random_state=random_state, class_weight='balanced', n_jobs=-1)\n",
    "model.fit(features_train_data_tf_idf, target_train)\n",
    "predictions = model.predict(features_valid_data_tf_idf)\n",
    "    \n",
    "avg_f1_score = f1_score(target_valid, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'Preprocessing model' : ['TF-IDF'],\n",
    "                        'Learning model' : ['LogisticRegression'], \n",
    "                        'Test f1 score' : round(avg_f1_score, 2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=random_state, class_weight = 'balanced', n_jobs=-1)\n",
    "model.fit(features_train_data_tf_idf, target_train)\n",
    "predictions = model.predict(features_valid_data_tf_idf)\n",
    "    \n",
    "avg_f1_score = f1_score(target_valid, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2 = pd.DataFrame({'Preprocessing model' : ['TF-IDF'],\n",
    "                        'Learning model' : ['RandomForestClassifier'], \n",
    "                        'Test f1 score' : round(avg_f1_score, 2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state=random_state, class_weight = 'balanced')\n",
    "model.fit(features_train_data_tf_idf, target_train)\n",
    "predictions = model.predict(features_valid_data_tf_idf)\n",
    "    \n",
    "avg_f1_score = f1_score(target_valid, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results3 = pd.DataFrame({'Preprocessing model' : ['TF-IDF'],\n",
    "                        'Learning model' : ['DecisionTreeClassifier'], \n",
    "                        'Test f1 score' : round(avg_f1_score, 2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Preprocessing model</th>\n",
       "      <th>Learning model</th>\n",
       "      <th>Test f1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Preprocessing model          Learning model  Test f1 score\n",
       "0              TF-IDF      LogisticRegression           0.75\n",
       "1              TF-IDF  RandomForestClassifier           0.61\n",
       "2              TF-IDF  DecisionTreeClassifier           0.64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = pd.concat([results, results2], ignore_index=True)\n",
    "results = pd.concat([results, results3], ignore_index=True)\n",
    "\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vs/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=random_state, class_weight='balanced', n_jobs=-1)\n",
    "model.fit(features_train_data_tf_idf, target_train)\n",
    "predictions = model.predict(features_test_data_tf_idf)\n",
    "    \n",
    "round(f1_score(target_test, predictions), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Данные загружены, состоят из 159571 строк и 2 столбцов\n",
    "* Столбец toxic является целевым признаком с выраженым дисбалансом классов\n",
    "* Токенизировали и лемматизировали столбец text и добавим данные в столбец text_final\n",
    "* Провели оценку важности слов определением величины TF-IDF\n",
    "* Проверили данные после векторизации\n",
    "* Обучили следующие модели:\n",
    "    * LogisticRegression\n",
    "    * RandomForestClassifier\n",
    "    * DecisionTreeClassifier\n",
    "* Лучший результат метрики F1-score 0.75 показала модель LogisticRegression\n",
    "* Другие модели не прошли по условию F1-score не меньше 0.75 и время обучения и предсказания намного выше чем у модели LogisticRegression\n",
    "* Модель LogisticRegression можно рекомендовать для использования в качестве инструмента, который будет искать токсичные комментарии и отправлять их на модерацию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
